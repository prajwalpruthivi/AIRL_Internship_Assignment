{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "55e21175",
      "metadata": {
        "id": "55e21175"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 0: installs & imports\n",
        "!pip install -q einops\n",
        "\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from einops import rearrange\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e9d29914",
      "metadata": {
        "id": "e9d29914",
        "outputId": "453f5a31-cbe6-485f-ed16-db3f4972559a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 1: config, reproducibility, device\n",
        "cfg = {\n",
        "    \"seed\": 42,\n",
        "    \"epochs\": 12,\n",
        "    \"batch_size\": 128,\n",
        "    \"lr\": 3e-4,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"patch_size\": 4,\n",
        "    \"embed_dim\": 128,\n",
        "    \"depth\": 6,\n",
        "    \"num_heads\": 4,\n",
        "    \"mlp_ratio\": 4.0,\n",
        "    \"dropout\": 0.1,\n",
        "    \"num_classes\": 10\n",
        "}\n",
        "\n",
        "random.seed(cfg[\"seed\"])\n",
        "np.random.seed(cfg[\"seed\"])\n",
        "torch.manual_seed(cfg[\"seed\"])\n",
        "torch.cuda.manual_seed_all(cfg[\"seed\"])\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "50680bb6",
      "metadata": {
        "id": "50680bb6",
        "outputId": "3c0f3656-830c-4388-af95-bbec86413762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [06:11<00:00, 459kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 50000 Test size: 10000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 2: CIFAR-10 data loaders\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "data_root = \"./data\"\n",
        "\n",
        "train_set = datasets.CIFAR10(root=data_root, train=True, download=True, transform=train_transform)\n",
        "test_set = datasets.CIFAR10(root=data_root, train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=cfg[\"batch_size\"], shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size=cfg[\"batch_size\"], shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Train size:\", len(train_set), \"Test size:\", len(test_set))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "04e3c27e",
      "metadata": {
        "id": "04e3c27e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 3: ViT implementation\n",
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size=32, patch_size=4, in_chans=3, embed_dim=128):\n",
        "        super().__init__()\n",
        "        assert img_size % patch_size == 0\n",
        "        self.patch_size = patch_size\n",
        "        self.n_patches_side = img_size // patch_size\n",
        "        self.n_patches = self.n_patches_side * self.n_patches_side\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, dropout=dropout)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, mlp_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(mlp_dim, dim),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_norm = self.norm1(x)\n",
        "        attn_out, _ = self.attn(x_norm.permute(1,0,2), x_norm.permute(1,0,2), x_norm.permute(1,0,2))\n",
        "        attn_out = attn_out.permute(1,0,2)\n",
        "        x = x + attn_out\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "class SimpleViT(nn.Module):\n",
        "    def __init__(self, img_size=32, patch_size=4, in_chans=3, num_classes=10, embed_dim=128, depth=6, num_heads=4, mlp_ratio=4., dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
        "        n_patches = self.patch_embed.n_patches\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, n_patches + 1, embed_dim))\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "\n",
        "        mlp_dim = int(embed_dim * mlp_ratio)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(embed_dim, num_heads, mlp_dim, dropout) for _ in range(depth)])\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        x = self.patch_embed(x)\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = x + self.pos_embed\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "        x = self.norm(x)\n",
        "        cls_out = x[:, 0]\n",
        "        return self.head(cls_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f94defb5",
      "metadata": {
        "id": "f94defb5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 4: instantiate model + optimizer\n",
        "model = SimpleViT(img_size=32, patch_size=cfg[\"patch_size\"], embed_dim=cfg[\"embed_dim\"],\n",
        "                  depth=cfg[\"depth\"], num_heads=cfg[\"num_heads\"], mlp_ratio=cfg[\"mlp_ratio\"],\n",
        "                  num_classes=cfg[\"num_classes\"]).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg[\"epochs\"])\n",
        "\n",
        "def accuracy_from_logits(logits, labels):\n",
        "    preds = logits.argmax(dim=1)\n",
        "    return (preds == labels).float().mean().item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "75d2187d",
      "metadata": {
        "id": "75d2187d",
        "outputId": "50dade34-72cb-4da3-f30b-e19d4bd510e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train acc: 33.72% | Test acc: 42.08%\n",
            "New best model saved (epoch 1) -> 42.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02 | Train acc: 46.15% | Test acc: 50.20%\n",
            "New best model saved (epoch 2) -> 50.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03 | Train acc: 51.70% | Test acc: 54.13%\n",
            "New best model saved (epoch 3) -> 54.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 | Train acc: 55.91% | Test acc: 59.37%\n",
            "New best model saved (epoch 4) -> 59.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05 | Train acc: 58.94% | Test acc: 61.29%\n",
            "New best model saved (epoch 5) -> 61.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06 | Train acc: 61.57% | Test acc: 63.59%\n",
            "New best model saved (epoch 6) -> 63.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07 | Train acc: 63.44% | Test acc: 66.04%\n",
            "New best model saved (epoch 7) -> 66.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08 | Train acc: 65.31% | Test acc: 66.76%\n",
            "New best model saved (epoch 8) -> 66.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09 | Train acc: 66.90% | Test acc: 68.98%\n",
            "New best model saved (epoch 9) -> 68.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | Train acc: 68.17% | Test acc: 69.28%\n",
            "New best model saved (epoch 10) -> 69.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 | Train acc: 69.26% | Test acc: 69.87%\n",
            "New best model saved (epoch 11) -> 69.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 | Train acc: 69.66% | Test acc: 70.00%\n",
            "New best model saved (epoch 12) -> 70.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 5: training loop\n",
        "best_acc = 0.0\n",
        "best_epoch = -1\n",
        "save_path = \"vit_cifar10_best.pth\"\n",
        "\n",
        "for epoch in range(1, cfg[\"epochs\"] + 1):\n",
        "    model.train()\n",
        "    running_loss, running_acc = 0.0, 0.0\n",
        "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{cfg['epochs']} - train\", leave=False):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        running_acc += accuracy_from_logits(logits, labels) * imgs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_set)\n",
        "    epoch_acc = running_acc / len(train_set)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    test_loss, test_acc = 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            test_loss += loss.item() * imgs.size(0)\n",
        "            test_acc += accuracy_from_logits(logits, labels) * imgs.size(0)\n",
        "\n",
        "    test_loss /= len(test_set)\n",
        "    test_acc /= len(test_set)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | Train acc: {epoch_acc*100:.2f}% | Test acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_epoch = epoch\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved (epoch {epoch}) -> {best_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dc4f2aa2",
      "metadata": {
        "id": "dc4f2aa2",
        "outputId": "d6196115-7ac2-4d9c-d1dc-8c991d189883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 70.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 6: final evaluation\n",
        "model.load_state_dict(torch.load(save_path, map_location=device))\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        logits = model(imgs)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "final_acc = 100.0 * correct / total\n",
        "print(f\"Final Test Accuracy: {final_acc:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}